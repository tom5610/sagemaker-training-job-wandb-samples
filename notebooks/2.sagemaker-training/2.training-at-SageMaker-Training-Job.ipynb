{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0e530f",
   "metadata": {},
   "source": [
    "## ML Training at SageMaker Training Job (with W&B)\n",
    "\n",
    "This is an example notebook to invoke SageMaker Training Job service for MNIST classification ML training. \n",
    "\n",
    "In the notebook, we will work through SageMaker Execution Role creation, W&B secret creation (for API key) and invoke SageMaker Training Job service. \n",
    "\n",
    "> For create IAM role, S3 bucket, secret and pass the created SageMaker Execution role, you will need proper IAM permissions for your client side. You may use AWS Managed Policy on your identity principal (IAM user / role) for the testing this example.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59436e58",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Enable scripts loading dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load scripts dynamically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf77802",
   "metadata": {},
   "source": [
    "Load environment variables from `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc31ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17973da8",
   "metadata": {},
   "source": [
    "Create SageMaker Execution Role if it doesn't exist. The key permissions for the IAM role is to:\n",
    "* download training image from ECR\n",
    "* read wandb secrets\n",
    "* add tags to sagemaker training job for marking wandb project & checkpoint so as for training resiliency \n",
    "* CloudWatch logs and metrics\n",
    "* S3 output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cddde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import create_sagemaker_execution_role, create_wandb_secret, create_s3_bucket\n",
    "\n",
    "iam_role = create_sagemaker_execution_role(\"sagemaker-execution-role\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad9b49",
   "metadata": {},
   "source": [
    "Create WANDB secret on AWS Secret Manager, which will be used in Training Job for integration on ML experimentation, tracking and checkpoint storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating api key secret\n",
    "wandb_secret_name = \"wandb-secret\"\n",
    "create_wandb_secret(wandb_secret_name, os.environ.get(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3202500",
   "metadata": {},
   "source": [
    "Create S3 bucket for SageMaker Training Job output. \n",
    "* Please ensure that the bucket naming pattern aligned with IAM role (by `create_sagemaker_execution_role` function) permissions.\n",
    "* Reference - with key word `sagemaker`:\n",
    "\n",
    "```\n",
    "{\n",
    "                \"Sid\": \"AllowS3ObjectActions\",\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:PutObject\",\n",
    "                    \"s3:DeleteObject\",\n",
    "                    \"s3:AbortMultipartUpload\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    \"arn:aws:s3:::*SageMaker*\",\n",
    "                    \"arn:aws:s3:::*Sagemaker*\",\n",
    "                    \"arn:aws:s3:::*sagemaker*\"\n",
    "                ]\n",
    "            },\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, creating the bucket in us-east-1 region without providing region parameter.\n",
    "bucket_name = \"sagemaker-wandb-samples\"\n",
    "create_s3_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f2cf1",
   "metadata": {},
   "source": [
    "### Setup SageMaker Training Job\n",
    "\n",
    "Please note that we are using SageMaker PyTorch pre-built training container for our ML training runtime. \n",
    "\n",
    "**Runtime customization**\n",
    "\n",
    "In my example, I need to install Python packages (including [PyTorch Lightning](https://lightning.ai/) and [Weights & Bias](https://wandb.ai/)) (aka. WANDB) for my runtime. To do so, I specify `source_dir` in  SageMaker Estimator `Pytorch`, which may pick up the [requirements.txt](./src/requirements.txt) for environment customization before running the training script.\n",
    "\n",
    "Meanwhile, [docker](./docker/) provides a reference on how to bake a custom image for ML training. In our example, we use [requirements.txt](./src/requirements.txt) for simplicity.\n",
    "\n",
    "**WANDB Integration**\n",
    "\n",
    "The purpose of the integration is to make ML experimentation on Amazon SageMaker, e.g. linage tracking for ML experiment, checkpoints, etc. To do so, I've create a WANDB secret (api key) in [AWS Secret Manager](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html). Before executing the training, it will enable WANDB integration for ML training with PyTroch Lightning. \n",
    "\n",
    "**Resume ML training when Cluster repairs for GPU errors**\n",
    "\n",
    "For deep learning model training, GPU errors are common and you may want to enable checkpoints so as to resume training once Sagemaker Cluster repair is done. To learn more about [Cluster repairs for GPU errors](https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints-cluster-repair.html).\n",
    "\n",
    "There are two options:\n",
    "\n",
    "> This notebook showcase option 2.\n",
    "\n",
    "1. Enable `checkpoint_s3_uri` parameter when creating a SageMaker Estimator object. With that, you could save ML training checkpoints into local folder `/opt/ml/checkpoints/`, which will be sync to the checkpoint S3 uri. When hardware repair occurs, SageMaker Training Job will automatically pull the latest checkpoint from the checkpoint S3 uri, which can be loaded to resume ML training.\n",
    "\n",
    "2. Downloading a latest checkpoints from WANDB so as to resume ML training. To do so, we are using `SageMakerTrainingJobTaggingCallback` in [training script](./src/train.py) to mark WANDB ML experimentation information, including `entity`, `project` and `checkpoint_name`, into tags associated with the training job. Such details will be useful when resuming ML training from WANDB checkpoint.\n",
    "\n",
    "In addition, when you are keen to resume ML training from a specific checkpoint from WANDB, you may specifying below variables in `environment` parameter on SageMaker Estimator:\n",
    "* `WANDB_SECRET_NAME` - the secret name\n",
    "* `AWS_DEFAULT_REGION` - the dedicated region for the secret. e.g. us-east-1\n",
    "* `WANDB_PROJECT` - the project in your WANDB workspace\n",
    "* [optional] `WANDB_CHECKPOINT_NAME` - if specified, it will be used to resume ML training.\n",
    "* [optional] `WANDB_CHECKPOINT_TAG` - if specified, the associated checkpoint will be used, otherwise, using 'latest' checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14147ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "\n",
    "instance_type = 'ml.g6.xlarge'\n",
    "training_job_output = f\"s3://{bucket_name}/training-jobs/\"\n",
    "\n",
    "# image uri when using Bring Your Own Container\n",
    "# image_uri = f\"{AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/mnist-training:latest\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    # image_uri=image_uri,\n",
    "    framework_version=\"2.7\",\n",
    "    py_version=\"py312\",\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./src\",\n",
    "    role=iam_role,\n",
    "    instance_type=instance_type, \n",
    "    instance_count=1,\n",
    "    volume_size=50,\n",
    "    output_path=training_job_output,\n",
    "    hyperparameters={\n",
    "        \"epochs\": 5\n",
    "    }, \n",
    "    environment={\n",
    "        \"WANDB_SECRET_NAME\": wandb_secret_name,\n",
    "        \"WANDB_PROJECT\": \"MNIST\",\n",
    "        \"AWS_DEFAULT_REGION\": region, # for training script to access region-based resources - secret.\n",
    "        # \"WANDB_CHECKPOINT_NAME\": \n",
    "        # \"WANDB_CHECKPOINT_TAG\": \"latest\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c2ad1",
   "metadata": {},
   "source": [
    "Kick off SageMaker Training Job. \n",
    "\n",
    "> We didn't provide data channel for the training as we are running a sample on `MNIST` classification problem, with which we will download training/evaluation/training data from torchvision dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2272ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c69e1e",
   "metadata": {},
   "source": [
    "To observe how a training job runs, please refer this [aws repost thread](https://repost.aws/knowledge-center/sagemaker-training-job-errors) for more details, e.g. checking related CloudWatch logs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9d7d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-training-job-wandb-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
